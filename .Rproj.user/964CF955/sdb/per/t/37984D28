{
    "contents" : "---\ntitle: \"CourseraMachineLearning\"\nauthor: \"JoshuaWei\"\ndate: \"October 25, 2015\"\noutput: html_document\n---\n\nOverview and Introduction: Utilizing devices with both accelerometers and gyrometers, we can get a rich amount of data to better parse the biomechanics of certain actions and motions. With this data, from new mobile monitoring machines like the fitbit, we can build a profile and predict the activity of an individual based on the profile of the action. With out dataset, there are some challenges needed to be addressed before we can proceed with analysis. Our basic protocol will involve a data scan and overview to understand what we're dealing with, data transformation and variable selection, our model fitting with a random forest (ensemble CART model), and cross validation.\n\nData Overview: We received two datasets, a training and a testing set. I began with a survey of the testing set, revealing both large number of observations and rows. There are 160 variables and 19622 observations. However we notice that a huge proportion of these columns are either incredibly sparse or simply 'NA.'\n\nprint(cars)\n```{R}\ntrainset<-read.csv(file=\"trainset.csv\", header=TRUE)\ntestset<-read.csv(file=\"testset.csv\", header=TRUE)\nprint(trainset)\n```\n\nVariable Selection: I decided to omit the majority of variables that have too many NAs or sparse variables. We would otherwise be forced to omit many observations if we decided to focus on those factors. We ended up settling on 41 factors, a combination of numerical and categorical data, that were not sparsely filled for our analysis.\n```{R}\nkeepvars <- c(\"v1\", \"v2\", \"v3\")\ntrainsetp <- trainset[keepvars]\n\t\t\t\n\n```\n\nDiscussion on Model Fitting: We attempt to address\n\n\n\n\n\n\n```{r}\na<-c(1,2,3)\n```\n\n\n\n\ncross Validation of Results:\n```{r}\nlibrary(plyr)\nlibrary(randomForest)\n\ndata <- iris\n\n# in this cross validation example, we use the iris data set to \n# predict the Sepal Length from the other variables in the dataset \n# with the random forest model \n\nk = 5 #Folds\n\n# sample from 1 to k, nrow times (the number of observations in the data)\ndata$id <- sample(1:k, nrow(data), replace = TRUE)\nlist <- 1:k\n\n# prediction and testset data frames that we add to with each iteration over\n# the folds\n\nprediction <- data.frame()\ntestsetCopy <- data.frame()\n\n#Creating a progress bar to know the status of CV\nprogress.bar <- create_progress_bar(\"text\")\nprogress.bar$init(k)\n\nfor (i in 1:k){\n  # remove rows with id i from dataframe to create training set\n  # select rows with id i to create test set\n  trainingset <- subset(data, id %in% list[-i])\n  testset <- subset(data, id %in% c(i))\n  \n  # run a random forest model\n  mymodel <- randomForest(trainingset$Sepal.Length ~ ., data = trainingset, ntree = 100)\n                                                     \n  # remove response column 1, Sepal.Length\n  temp <- as.data.frame(predict(mymodel, testset[,-1]))\n  # append this iteration's predictions to the end of the prediction data frame\n  prediction <- rbind(prediction, temp)\n  \n  # append this iteration's test set to the test set copy data frame\n  # keep only the Sepal Length Column\n  testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,1]))\n  \n  progress.bar$step()\n}\n\n# add predictions and actual Sepal Length values\nresult <- cbind(prediction, testsetCopy[, 1])\nnames(result) <- c(\"Predicted\", \"Actual\")\nresult$Difference <- abs(result$Actual - result$Predicted)\n\n# As an example use Mean Absolute Error as Evalution \nsummary(result$Difference)\n```\n\n",
    "created" : 1445794471755.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1285280878",
    "id" : "37984D28",
    "lastKnownWriteTime" : 1445796334,
    "path" : "C:/Users/577731/Desktop/Coursera/Rmarkdown.Rmd",
    "project_path" : "Rmarkdown.Rmd",
    "properties" : {
        "tempName" : "Untitled2"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_markdown"
}