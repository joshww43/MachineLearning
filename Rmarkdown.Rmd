---
title: "CourseraMachineLearning"
author: "JoshuaWei"
date: "October 25, 2015"
output: html_document
---

Overview and Introduction: Utilizing devices with both accelerometers and gyrometers, we can get a rich amount of data to better parse the biomechanics of certain actions and motions. With this data, from new mobile monitoring machines like the fitbit, we can build a profile and predict the activity of an individual based on the profile of the action. With out dataset, there are some challenges needed to be addressed before we can proceed with analysis. Our basic protocol will involve a data scan and overview to understand what we're dealing with, data transformation and variable selection, our model fitting with a random forest (ensemble CART model), and cross validation.

Data Overview: We received two datasets, a training and a testing set. I began with a survey of the testing set, revealing both large number of observations and rows. There are 160 variables and 19622 observations. However we notice that a huge proportion of these columns are either incredibly sparse or simply 'NA.'

print(cars)
```{R}
trainset<-read.csv(file="trainset.csv", header=TRUE)
testset<-read.csv(file="testset.csv", header=TRUE)
print(trainset)
```

Variable Selection: I decided to omit the majority of variables that have too many NAs or sparse variables. We would otherwise be forced to omit many observations if we decided to focus on those factors. We ended up settling on 41 factors, a combination of numerical and categorical data, that were not sparsely filled for our analysis.
```{R}
keepvars <- c("v1", "v2", "v3")
trainsetp <- trainset[keepvars]
			

```

Discussion on Model Fitting: We attempt to address






```{r}
a<-c(1,2,3)
```




cross Validation of Results:
```{r}
library(plyr)
library(randomForest)

data <- iris

# in this cross validation example, we use the iris data set to 
# predict the Sepal Length from the other variables in the dataset 
# with the random forest model 

k = 5 #Folds

# sample from 1 to k, nrow times (the number of observations in the data)
data$id <- sample(1:k, nrow(data), replace = TRUE)
list <- 1:k

# prediction and testset data frames that we add to with each iteration over
# the folds

prediction <- data.frame()
testsetCopy <- data.frame()

#Creating a progress bar to know the status of CV
progress.bar <- create_progress_bar("text")
progress.bar$init(k)

for (i in 1:k){
  # remove rows with id i from dataframe to create training set
  # select rows with id i to create test set
  trainingset <- subset(data, id %in% list[-i])
  testset <- subset(data, id %in% c(i))
  
  # run a random forest model
  mymodel <- randomForest(trainingset$Sepal.Length ~ ., data = trainingset, ntree = 100)
                                                     
  # remove response column 1, Sepal.Length
  temp <- as.data.frame(predict(mymodel, testset[,-1]))
  # append this iteration's predictions to the end of the prediction data frame
  prediction <- rbind(prediction, temp)
  
  # append this iteration's test set to the test set copy data frame
  # keep only the Sepal Length Column
  testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,1]))
  
  progress.bar$step()
}

# add predictions and actual Sepal Length values
result <- cbind(prediction, testsetCopy[, 1])
names(result) <- c("Predicted", "Actual")
result$Difference <- abs(result$Actual - result$Predicted)

# As an example use Mean Absolute Error as Evalution 
summary(result$Difference)
```

